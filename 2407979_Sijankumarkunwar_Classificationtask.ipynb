{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMQjVSue3T2bBW3cK1xbZOB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8rfwTc8X3tvX","outputId":"17c71e7b-5060-4f58-f92f-1c08bfede430","executionInfo":{"status":"ok","timestamp":1738642454947,"user_tz":-345,"elapsed":835875,"user":{"displayName":"Sijan Kumar Kunwar","userId":"01553313185327775676"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Gradient Boosting - Accuracy: 0.5476864966949953\n","Gradient Boosting - Precision: 0.5644983461962514\n","Gradient Boosting - Recall: 0.8590604026845637\n","Gradient Boosting - F1-Score: 0.6813040585495675\n","Fitting 3 folds for each of 54 candidates, totalling 162 fits\n","Best Gradient Boosting Parameters: {'learning_rate': 0.01, 'max_depth': None, 'n_estimators': 100, 'subsample': 0.8}\n","Optimized Gradient Boosting - Accuracy: 0.5599622285174694\n","Optimized Gradient Boosting - Precision: 0.5687103594080338\n","Optimized Gradient Boosting - Recall: 0.9026845637583892\n","Optimized Gradient Boosting - F1-Score: 0.6977950713359273\n"]}],"source":["# Step 1: Mount Google Drive (already done, you can skip this in future sessions)\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 2: Import necessary libraries\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.model_selection import GridSearchCV\n","\n","# Step 3: Load the dataset from the correct path\n","file_path = '/content/drive/My Drive/Aiportfolio/diabetes_prediction_india .csv'  # Correct path to the dataset\n","df = pd.read_csv(file_path)\n","\n","# Step 4: Prepare the data (for classification)\n","# Classify based on glucose test result threshold (e.g., 126 mg/dL is the threshold for diabetes diagnosis)\n","y = df['Glucose_Tolerance_Test_Result'].apply(lambda x: 1 if x >= 126 else 0)  # 1 = Diabetic, 0 = Non-diabetic\n","\n","# Prepare the features (exclude 'Glucose_Tolerance_Test_Result')\n","X = df.drop(columns=['Glucose_Tolerance_Test_Result'])\n","\n","# Convert categorical variables to dummy variables\n","X = pd.get_dummies(X, drop_first=True)\n","\n","# Step 5: Split the dataset into training and testing sets (80-20 split)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Step 6: Scale the data (standardize features)\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# Step 7: Model Selection - Gradient Boosting Classifier\n","# We will try Gradient Boosting Classifier as it often performs better in classification tasks\n","gb_model = GradientBoostingClassifier(random_state=42)\n","gb_model.fit(X_train_scaled, y_train)\n","\n","# Make predictions on the test set\n","y_pred_gb = gb_model.predict(X_test_scaled)\n","\n","# Evaluate the Gradient Boosting model\n","accuracy_gb = accuracy_score(y_test, y_pred_gb)\n","precision_gb = precision_score(y_test, y_pred_gb)\n","recall_gb = recall_score(y_test, y_pred_gb)\n","f1_gb = f1_score(y_test, y_pred_gb)\n","\n","print(f\"Gradient Boosting - Accuracy: {accuracy_gb}\")\n","print(f\"Gradient Boosting - Precision: {precision_gb}\")\n","print(f\"Gradient Boosting - Recall: {recall_gb}\")\n","print(f\"Gradient Boosting - F1-Score: {f1_gb}\")\n","\n","# Step 8: Hyperparameter Optimization (GridSearchCV)\n","# Let's define a grid for hyperparameter tuning to optimize Random Forest and Gradient Boosting\n","param_grid = {\n","    'n_estimators': [100, 200, 300],\n","    'max_depth': [10, 20, None],\n","    'learning_rate': [0.01, 0.1, 0.5],\n","    'subsample': [0.8, 1.0]\n","}\n","\n","# Use GridSearchCV to find the best parameters for Gradient Boosting\n","grid_search = GridSearchCV(estimator=GradientBoostingClassifier(random_state=42), param_grid=param_grid,\n","                           cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n","\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Get the best parameters and model\n","best_gb_model = grid_search.best_estimator_\n","\n","# Make predictions with the best model\n","y_pred_best_gb = best_gb_model.predict(X_test_scaled)\n","\n","# Evaluate the optimized Gradient Boosting model\n","accuracy_best_gb = accuracy_score(y_test, y_pred_best_gb)\n","precision_best_gb = precision_score(y_test, y_pred_best_gb)\n","recall_best_gb = recall_score(y_test, y_pred_best_gb)\n","f1_best_gb = f1_score(y_test, y_pred_best_gb)\n","\n","print(f\"Best Gradient Boosting Parameters: {grid_search.best_params_}\")\n","print(f\"Optimized Gradient Boosting - Accuracy: {accuracy_best_gb}\")\n","print(f\"Optimized Gradient Boosting - Precision: {precision_best_gb}\")\n","print(f\"Optimized Gradient Boosting - Recall: {recall_best_gb}\")\n","print(f\"Optimized Gradient Boosting - F1-Score: {f1_best_gb}\")\n","\n"]},{"cell_type":"code","source":[],"metadata":{"id":"3Bx6280p4Gc2"},"execution_count":null,"outputs":[]}]}